---
title: 'Stat 3302: Final Project'
author: "Zhengqi Dong"
date: "3/14/2020"
output:
  html_document: default
  pdf_document: 
    latex_engine: xelatex
---

## 1. Importing library, defining function, and checking data
```{r setup, include=FALSE}
# Basic package
library(tidyverse)
library(broom)
library(readr)
library(ggplot2)
# Advanced(Fancy) package
library(ggthemes)
library(gridExtra)
# This allows you to set default behavior for R chunks
knitr::opts_chunk$set(echo = TRUE)
```


### 1.1 Import dataset:
```{r include=F, echo=F}
set.seed(1)
train <- read.csv("train.csv", stringsAsFactors = F)
test <- read.csv('test.csv', stringsAsFactors = F)
full  <- bind_rows(train, test) # bind training & test data
```

### 1.2 Checking dataset
```{r}
str(train)
str(test)
str(full)
```
Our training dataset contains 891 observation and 12 variable; testing dataset contains 418 observation with missed variable “Survived” (That's the variable we want to predict with for testing dataset); full dataset contains 1309 observation and 12 variables.

### 1.3 Background description:
The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.

![Titanic_sinking.jpg](Titanic_sinking.jpg)
[Reference](https://www.kaggle.com/c/titanic)


## 2. EDA

### 2.1 Age vs Survived

```{r}
# Age vs Survived
ggplot(full[1:891,], aes(Age, fill = factor(Survived))) + 
  theme_few()+
  geom_histogram(bins=30) + 
  ggtitle("Age vs Survived") + 
  scale_fill_discrete(name = "Survived") # For the label in the right
```
Note: 1)People who are in range between 20 to 50 are less likely being survived, and the people who below age 10 are more likely being survived. 2)The distribution of age looks like a right skewed distribution.

The warning tell us, there are 177 missing value. So, let's imputing those missing age values. There are many way to take care the missing value, such as remove the data, or filling with zero or NaN. But, we can do better than that. A decent way to do this is to create a model that predicts the average ages based on other variables. There are many package can do this interpolation, such as rpart(recursive partitioning for regression), and mice(Multivariate Imputation by Chained Equations). [reference for mice](http://www.jstatsoft.org/article/view/v045i03/v45i03.pdf). Let's try the mice library: 
```{r}
library('mice') # imputation
# Show number of missing Age values in training set
sum(is.na(full[1:891,]$Age)) # => 177

# Make variables factors into factors
# factor_vars <- c('PassengerId','Pclass','Sex','Embarked', 'Surname','Family')
# 
# full[factor_vars] <- lapply(full[factor_vars], function(x) as.factor(x))

mice_mod <- mice(full[, !names(full) %in% c('PassengerId','Name','Ticket','Cabin','Family','Surname','Survived')], method='rf') 

mice_output <- complete(mice_mod)

# Plot age distributions
par(mfrow=c(1,2))
hist(full$Age, freq=F, main='Age: Original Data', 
  col='darkgreen', ylim=c(0,0.04))
hist(mice_output$Age, freq=F, main='Age: MICE Output', 
  col='lightgreen', ylim=c(0,0.04))
```
The result look pretty good, so let’s replace our age vector in the original data with the output from the mice model.
```{r}
# Replace Age variable from the mice model.
full$Age <- mice_output$Age

# Show new number of missing Age values
sum(is.na(full$Age))
```
Now, the missing value is gone!

### 2.2 Sex Vs Survive
```{r}
# Sex vs Survived
ggplot(full[1:891,], aes(Sex, fill = factor(Survived))) + 
  geom_bar(stat = "count", position = 'dodge')+
  xlab("Sex") +
  ggtitle("Sex vs Survived") +
  geom_label(stat='count',aes(label=..count..))+
  scale_fill_discrete(name = "Survived") # For the label in the right
```
Note: 1)female is more likely being survived than male, femail survived rate roughly 75%, and male is roughly 16.7%, so almost 5 time greater!

### 2.3 Age Vs Sex Vs Survived
```{r}
#Sex vs Survived vs Age 
ggplot(full[1:891,], aes(Age, fill = factor(Survived))) + 
  geom_histogram(bins=30) + # bins: controls the width of bar, so larger the thinner. You can use geom_bar() if you don't want to specify it!
  xlab("Age") +
  facet_grid(.~Sex)+
  ggtitle("Age vs Sex vs Survived") +
  # geom_label(stat='count',aes(label=..count..)) +
  scale_fill_discrete(name = "Survived") # For the label in the right

```
Note: 1) Again, female is more likely being survived than male. 2) The differences between the number of peoples survived and not survived is largest at roughly age 20to30, and this is true for both female and male.

### 2.4. Pclass vs Sex
```{r}
# geom_bar vs geom_hist: 
#   - Bar charts provide a visual presentation of categorical data
#   - Histograms are used to plot the distribution of data

# Pclass vs Sex Vs Survived
p1 <- ggplot(full[1:891,], aes(Pclass, fill = factor(Survived))) + 
  geom_bar(stat='count') + 
  xlab("Pclass") +
  facet_grid(.~Sex)+
  ggtitle("Pclass vs Sex vs Survived") +
  geom_label(stat='count',aes(label=..count..)) +
  scale_fill_discrete(name = "Survived") # For the label in the right

p2 <- ggplot(full[1:891,], aes(x = Pclass, fill = factor(Survived))) +
  geom_bar(stat='count', position='fill') +
  labs(x = 'Passenger class', y= "Percent") + 
  facet_grid(.~Sex) +
  theme(legend.position="none")
grid.arrange(p1, p2, ncol=2)
```
Note: 1) female is more likely of being survived than male in average. 2)In female group, majority passengers in class 1 and class 2 are survived, and more people in classed died. However, in male group, the survived rate in class 2 (~18.7%) just as bad as class 3(~15.67%). 

### 2.5 Pclass Vs Embarked 
Let's removed the missing value at first
```{r}
full[c(62, 830), 'Embarked']

# Get rid of our missing passenger IDs
embark_fare <- full %>%
  filter(PassengerId != 62 & PassengerId != 830)

# Use ggplot2 to visualize embarkment, passenger class, & median fare
ggplot(embark_fare, aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80), 
  colour='red', linetype='dashed', lwd=2) +
  theme_few()

```
Notice that missing value in the marning message:
```{r}
# Since their fare was $80 for 1st class, they most likely embarked from 'C'
full$Embarked[c(62, 830)] <- 'C'
# Replace missing fare value with median fare for class/embarkment
full$Fare[1044] <- median(full[full$Pclass == '3' & full$Embarked == 'S', ]$Fare, na.rm = TRUE)
```

Replace their embarkment with "C"
```{r}
train[c(62, 830), 'Embarked']   # => [1] "" ""
# Let's delete them
# train <- train %>%  filter(PassengerId != 62 & PassengerId != 830)
# Instead of delete them it's better to replace their embarkment with "C", since there fare was $80 for 1st class.
train$Embarked[c(62, 830)] <- c("C", "C")
# show the table of counts
count_table <- table(train$Embarked, train$Survived)
count_table

```
```{r}
round(count_table / apply(count_table, 1, sum), 3)
```

## 3. Processing data and Further EDA
Notices, there are some useful infromation in passenger name, what is it? For example: the passenger title!(e.g. Ms, Miss, Mrs..) So, we can use this information to ask some question like, is there any relationship between the passenger title and probability of survived? Also, The surname can be useful as well. It allow us to use "surname" to represent a families. 
Now, let's create a new variables, called title.
### 3.1 Feature Engineer work:
```{r}
# Grab title from passenger names
full$Title <- gsub('(.*, )|(\\..*)', '', full$Name)

cat("Show title counts by sex:")
table(full$Sex, full$Title)
# kable(table(full$Sex, full$Title)) # A fance table for html presentation

# Titles with very low cell counts to be combined to "rare" level
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 
                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')

# Also reassign mlle, ms, and mme accordingly
full$Title[full$Title == 'Mlle']        <- 'Miss' 
full$Title[full$Title == 'Ms']          <- 'Miss'
full$Title[full$Title == 'Mme']         <- 'Mrs' 
full$Title[full$Title %in% rare_title]  <- 'Rare Title'

cat("\nShow title counts by sex after merged title has very few count in the data: ") 
table(full$Sex, full$Title)

# Finally, grab surname from passenger name
full$Surname <- sapply(full$Name,  
                      function(x) strsplit(x, split = '[,.]')[[1]][1])
cat("\nHead of full$Surname:\n")
head(full$Surname)
```

### 3.2 Title Vs Survived
```{r}
ggplot(full[1:891,], aes(x = Title, fill = factor(Survived))) +
  geom_bar(stat='count', position='stack') +
  ggtitle("Title Vs Survived") +
  geom_label(stat='count',aes(label=..count..)) +
  scale_fill_discrete(name = "Survived") # For the label in the right
```
Note: we see the Mr. "Mr" are died pretty badly, which proved our previous observation that male are less likely being survived than female.


### 3.3 Family size Vs Survived
Family size might be a interesting predictor for evaluating the probabilty of being survived. So, let's use the sum of "sibsp" and "parch" to create another new variable, and then we can analysis there relationship!
Create variable Fsize, which is sum of the number of siblings/spouses and number of chldren/parens and one(The person himself)
```{r}
# Create a family size variable including the passenger themselves
full$Fsize <- full$SibSp + full$Parch + 1

# Create a family variable 
full$Family <- paste(full$Surname, full$Fsize, sep='_')
head(full$Family)
```


```{r}
# Use ggplot2 to visualize the relationship between family size & survival
ggplot(full[1:891,], aes(x = Fsize, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  scale_x_continuous(breaks=c(1:11)) +
  ggtitle("Family size Vs Survived") + 
  labs(x = 'Family Size') +
  # geom_label(stat='count',aes(label=..count..)) +
  scale_fill_discrete(name = "Survived") # For the label in the right

```
Note: By comparing the "family size" and "Survived", we noticed the singleton, familes sizes 1, and large families (size > 5) are less likely being survived than the family with size between 2 and 4. Keep this in mind, that might be something we want to use in building our regression model.



## 4. Building SLLR model: 
Produce a table including the pclass factor variable, number of passenger survived(survival=1) in each class, and the total number of passenger in each class(survival=1 or 0)

Response variable:
  - survived (0 == died, 1 == survived)
Explanatory variables/covaraite of interest:
 - Pclass
 - Sex
 - Age
 - Fsize
 
Define the function to be used:
```{r}
## Define the logit function.
logit <- function (p) 
{
  log(p / (1 - p))
}

## Define the inverse logit function.
sigmoid <- function (etas) 
{
  exp(etas) / (1 + exp(etas))
}

```

### 4.1 Redefined the variable to factor: 
Because the purpose of this project is to build a logistic regression model(binary), in order to make the varaible "Fsize" to be more useful and easier to deal with, we need to convert it to factor! (as well as other categorical variables. Factor just a nice data type in R, that is design for categorical variable.)


```{r}
set.seed(1)
train <- full[1:891,]
## define 'Survived' to be 1 if any passenger survived; 0 if died
train$Survived <- as.numeric(train$Survived == 1)


## define the variable 'Sex'
## is 0 if Sex is light medium or medium.
## is 1 if color is dark medium or dark.
# Sex <- factor(ifelse(crabs$color <= 2, "not dark", "dark"))
train$Sex <- factor(train$Sex)

## Redefine the Pclass factor variable ordered as
## 1: Class_1, 2: Class_2, 3: Class_3, Otherwise: Error.
## (factors by default are ordered alphabetically)
train$Pclass <-
  factor(ifelse(train$Pclass==1, "Class_1",
                ifelse(train$Pclass==2, "Class_2",
                       ifelse(train$Pclass==3, "Class_3", "Error"))),
         levels=c("Class_1", "Class_2", "Class_3"))

## Redefine the Fsize factor variable ordered as
## 1: solo, 2: double, 3: Fsize_3, 4: Fsize_4, 5: large_family
## (factors by default are ordered alphabetically)
# train$Fsize <-
#   factor(ifelse(train$Fsize==1, "solo",
#             ifelse(train$Fsize==2, "double",
#               ifelse(train$Fsize==3, "Fsize_3",
#                 ifelse(train$Fsize==4, "Fsize_4", "large_family")))),
#          levels=c("solo", "double", "Fsize_3", "Fsize_4", "large_family"))

# Alternatively: 
train$Fsize[train$Fsize>=5] <- 'large_family' # THis must go first, otherwise it won't work
train$Fsize[train$Fsize==1] <- 'solo'
train$Fsize[train$Fsize==2] <- 'double'
train$Fsize[train$Fsize==3] <- 'Fsize_3'
train$Fsize[train$Fsize==4] <- 'Fsize_4'
train$Fsize <- as.factor(train$Fsize)
# levels(train$Fsize) <- c("solo","double","Fsize_3","Fsize_4","large_family")

factor_vars <- c('Pclass','Sex','Embarked', 'Title','Surname','Family','Fsize')

train[factor_vars] <- lapply(train[factor_vars], function(x) as.factor(x))
```


```{r}
# Fsize Vs Survived
ggplot(train[!is.na(full$Survived),], aes(x = Fsize, fill = factor(Survived))) +
  geom_bar(stat='count', position='dodge') +
  ggtitle("Family size Vs Survived") + 
  labs(x = 'Family Size') +
  # geom_label(stat='count',aes(label=..count..)) +
  scale_x_discrete (limits = c('solo', 'double', 'Fsize_3', 'Fsize_4', 'large_family')) +
  scale_fill_discrete(name = "Survived") # For the label in the right
```

### 4.2 SLLR on Survived~Age
```{r eval=FALSE, include=FALSE}
rounded_age <- round(train$Age*2)/2
count_table <- table(rounded_age, train$Survived)
prob_survived <- round(count_table / apply(count_table, 1, sum), 3)[,2]
```

```{r eval=FALSE, include=FALSE}
plot(sort(unique(rounded_age)), logit(prob_survived),
     xlab="weight (to nearest 0.5kg)", ylab="proportion")
```


```{r}
Survived_age_model <- glm(train$Survived ~ train$Age, family=binomial)
summary(Survived_age_model)
anova(Survived_age_model, test="Chisq")
```

p-value(>|Z|) tells us, the coefficient for age is sig different from zero, and has a negative relationship with survived. The pr(>Chi) tells us it's useful to include Age into our model, which decreased AIC from 964.52 to 960.23.

### 4.3 SLLR on Survived~Sex

```{r}
# show the table of counts
count_table <- table(train$Sex, train$Survived)
count_table
```

```{r}
# show the table of proportions: p_ij = r_ij/(r_i + r_j): 
round(count_table / apply(count_table, 1, sum), 3)
```
En, looks like female has a high probability of being survived!

```{r}
# fit the glm with Sex: 
Survived_sex_model <- glm(train$Survived ~ train$Sex, family=binomial)
summary(Survived_sex_model)
anova(Survived_sex_model, test="Chisq")
```

p-value(>|Z|) tells us, the coefficient for age is sig different from zero, and the expected probability of being survived for male is $e^{-2.5137} * 100% = 8.097% $ less than the female in average. The pr(>Chi) tells us it's useful to include sex into our model, which reduced the AIC from 1186.7 to 917.8.

### 4.4 SLLR on Survived~Pclass
```{r}
# show the table of counts
count_table <- table(train$Pclass, train$Survived)
count_table
```

```{r}
# show the table of proportions: p_ij = r_ij/(r_i + r_j): 
round(count_table / apply(count_table, 1, sum), 3)
```
En, looks like the passenger classes does related to the probability of survived, the higher the classes and low the probability of being survived. 

```{r}
# fit the glm with Pclass: 
Survived_pclass_model <- glm(train$Survived ~ train$Pclass, family=binomial)
summary(Survived_pclass_model)
anova(Survived_pclass_model, test="Chisq")
```
p-value(>|Z|) tells us, the coefficient for Pclass is sig different from zero. The pr(>Chi) tells us it's useful to include Pclass into our model, which reduced the AIC from 1186 to 1084.4.

### 4.5 SLLR on Survived~Fsize
```{r}
# show the table of counts
count_table <- table(train$Fsize, train$Survived)
count_table
```

```{r}
# show the table of proportions: p_ij = r_ij/(r_i + r_j): 
round(count_table / apply(count_table, 1, sum), 3)
```
En, seems like the probability of survived is increased and then decreased for the familiy size over 4, so it might not be a linear relationship.

```{r}
# levels(train$Fsize) <- c("solo","double","Fsize_3","Fsize_4","large_family")
# fit the glm with Fsize: 
Survived_Fsize_model <- glm(train$Survived ~ train$Fsize, family=binomial)
summary(Survived_Fsize_model)
anova(Survived_Fsize_model, test="Chisq")
```
p-value(>|Z|) tells us, only the coefficient for solo and Fsize_3 is sig different from zero. The pr(>Chi) tells us it's useful to include Fsize into our model, which reduced the AIC from 1186.7 to 1108.5.

### 4.5 SLLR on Survived~Title:
```{r}
# show the table of counts
count_table <- table(train$Title, train$Survived)
count_table
```

```{r}
# show the table of proportions: p_ij = r_ij/(r_i + r_j): 
round(count_table / apply(count_table, 1, sum), 3)
```
En, seems like the probability of survived is increased and then decreased for the familiy size over 4, so it might not be a linear relationship.

```{r}
# levels(train$Fsize) <- c("solo","double","Fsize_3","Fsize_4","large_family")
# fit the glm with Fsize: 
Survived_title_model <- glm(train$Survived ~ train$Title, family=binomial)
summary(Survived_title_model)
anova(Survived_title_model, test="Chisq")
```



Let's summarize the AIC for the above models: 
* Survived~Age: 960.23
* Survived~Sex: 917.8
* Survived~Pclass: 1084.4
* Survived~Fsize: 1108.5
* Survived~Title: 886.59

Seems like Survived~Title has the lowest AIC score so far, so we might want to consider it as our baseline model, and then we will build our model based on stepwise selection mechanism. [referece for stepwise](http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/)

What covariate do we have for now? (Age, Sex, Pclass, Fsize, Title, Embarked).
However, for the sake of our time, let's build a small model at first. So we will only consider three covarate, which appears has the smallest AIC in our discovery: Age, Title, Sex
### 4.6 SLLR on Survived~Title + Sex
```{r}
Survived_age_Title_model <- glm(train$Survived ~ train$Title+train$Sex, family=binomial)
summary(Survived_age_Title_model)
anova(Survived_age_Title_model, test="Chisq")
```

###4.7  SLLR on Survived~Age + Title + Sex
```{r echo=TRUE}
Survived_model1 <- glm(train$Survived ~ train$Age + train$Pclass + train$Sex, family=binomial)
summary(Survived_model1)
anova(Survived_model1, test="Chisq")
# cov(train %>% select(c(Age, Sex, Fsize, Embarked, Fare, Ticket)))
```

### 4.8 SLLP with interaction terms: Survived~Age + Title + Sex
```{r}
Survived_model1 <- glm(train$Survived ~ train$Title * train$Pclass * train$Sex, family=binomial)
summary(Survived_model1)
anova(Survived_model1, test="Chisq")
```
With some interaction terms, we notice that the Deviance Residual had dicreased, but not substantially. 
I think the reason is because that there might exist a very high correlation between those variables, so not too much variance can be explained by adding new terms. Also we can see that the degree of freedom is pretty big here(over 800), so if we applied the PCA technique to reduced the amount of features/variables and then picked several most important component as our representative variables, it's possible that we could get a better predictive model!

### 4.9 SLLP with interaction terms: Survived~Title + Sex + Pclass
```{r}
Survived_model1 <- glm(train$Survived ~ train$Title * train$Pclass * train$Sex, family=binomial)
summary(Survived_model1)
anova(Survived_model1, test="Chisq")
```

## 5. Model diagnostic

```{r}
## produce the default diagnostic plots
par(mfrow=c(2,2))
plot(Survived_model1)


## calculate the fitted values.
fits  <- fitted(Survived_model1)

## calculate the deviance residuals
dev.resids  <- resid(Survived_model1)
pear.resids <- as.numeric(resid(Survived_model1, type="pearson"))


par(mfrow=c(2,2), cex=0.65, mar=c(4, 4, 2.3, 0.2), bty="L")

plot(fits, dev.resids,
     xlab="fitted values", ylab="Deviance residuals", ylim=c(-2,2))
abline(h=0, lty=2) 

plot(fits, pear.resids,
     xlab="fitted values", ylab="Pearson residuals", ylim=c(-2,2))
abline(h=0, lty=2)


qqnorm(dev.resids,
       xlab="Std. normal quantiles", ylab="Deviance residuals", main="",
       xlim=c(-2,2), ylim=c(-2,2))
qqline(dev.resids)

qqnorm(pear.resids,
       xlab="Std. normal quantiles", ylab="Pearson residuals", main="",
       xlim=c(-2,2), ylim=c(-2,2))
qqline(pear.resids)

```
Haha, so the residual doesn't work very well in this case, and that's because the number of success(survived), m_i = 1, for each person(i) is one, which is like Bernoulli distribution, so that's kinda of missleading.

Now, there are only three things we should care about, 1)) Devidance residual, 2)df(degree of freedom), and 3)p-value (With Chi-square dist). 
Let's use deviance table to help us figure out what is the best model here!



## 6. Conclusion
Stat 3302 Project Rubric: You may want to include some discussion of your results and ideas for further analysis at the end of the report. If you have references, format them appropriately. e.g., appropriateness of conclusions drawn understanding of implications and limitations possibilities for further work/extension

* The best model is: 
(Write the fitted model; the model comparion criteris, e.g. AIC, Deviance..; discuss the result of diagnostic plot, and use it to answer the original scientific question.)




## (Opt)8. Making Prediction

### 8.1 Modeling with Random Forest
```{r eval=FALSE, include=FALSE}
train <- full[1:891,]
test <- full[892:1309,]

# random forest
library('randomForest')

# Set a random seed
set.seed(754)

set.seed(123)
rf_model <- randomForest(factor(Survived) ~ Pclass + Sex + Fare + Embarked + Title + Fsize, data = train)
```


## Scientific question: What sorts of people were more likely to survive the Titanic sinking?

## Step 1: EDA

### b.1) Produce a graphical summary that display the relationship between the probability of survival and the factor variable pclass. 

### b.2) Produce a graphical summary that display the relationship between the logit of the probability of survival and the factor variable pclass. 

### c) Fit a model that estimates the logit of the probability of survival in terms of pclass factor variables. Write out the assumed model and define your notation.

### d) Summarize the fitted model and analysis of deviance table.

### e) Discuss the result and idea, is this model help us to understand the scientific question? (What sorts of people were more likely to survive.)

### f) (Option)Interpret this statistical model in terms of changes of the odds with appropriate confidence interval (including at least one confidence intervals for the quantities that you estimated.)


## Step2: Do the same things in terms of factor variable gender

### g)Compare the factor model from above with the model from Step1, using deviance, AICs, and residual plots, which model do you prefer? Why?

## Step3: Do the same things in terms of factor variable Embarked

## Step4: Do the same things in terms of continuous variable age

## Step5: Do the same things in terms of continuous variable fare

## Conclusion: Compare the models from previous step, using deviance, AICs, and residual plots, which model do you prefer? Why?

## Appendix (The R code you need to support previous argument, not counted in the 5–6 page limit)

